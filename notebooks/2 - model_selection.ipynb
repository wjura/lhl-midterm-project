{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "This notebook should include preliminary and baseline modeling.\n",
    "- Try as many different models as possible.\n",
    "- Don't worry about hyperparameter tuning or cross validation here.\n",
    "- Ideas include:\n",
    "    - linear regression\n",
    "    - support vector machines\n",
    "    - random forest\n",
    "    - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data from \n",
    "\n",
    "X_train = pd.read_csv('../data/preprocessed/X_train.csv')\n",
    "X_test = pd.read_csv('../data/preprocessed/X_test.csv')\n",
    "y_train = pd.read_csv('../data/preprocessed/y_train.csv')\n",
    "y_train = y_train.values.ravel() # Change pd df to 1d numpy array\n",
    "y_test = pd.read_csv('../data/preprocessed/y_test.csv')\n",
    "y_test = y_test.values.ravel() # Change pd df to 1d numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "linear_reg = LinearRegression()\n",
    "svm_reg = SVR()\n",
    "rf_reg = RandomForestRegressor()\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "\n",
    "# Fit models\n",
    "linear_reg.fit(X_train, y_train)\n",
    "svm_reg.fit(X_train, y_train)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_linear = linear_reg.predict(X_test)\n",
    "y_pred_svm = svm_reg.predict(X_test)\n",
    "y_pred_rf = rf_reg.predict(X_test)\n",
    "y_pred_xgb = xgb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models and fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what metrics you want to use to evaluate success.\n",
    "- If you think about mean squared error, can we actually relate to the amount of error?\n",
    "- Try root mean squared error so that error is closer to the original units (dollars)\n",
    "- What does RMSE do to outliers?\n",
    "- Is mean absolute error a good metric for this problem?\n",
    "- What about R^2? Adjusted R^2?\n",
    "- Briefly describe your reasons for picking the metrics you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather evaluation metrics and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>131319.802810</td>\n",
       "      <td>1.852624e+11</td>\n",
       "      <td>430421.150297</td>\n",
       "      <td>0.298296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>215308.010480</td>\n",
       "      <td>2.748053e+11</td>\n",
       "      <td>524218.750852</td>\n",
       "      <td>-0.040858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>40837.795086</td>\n",
       "      <td>1.498777e+11</td>\n",
       "      <td>387140.385611</td>\n",
       "      <td>0.432320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>41733.465233</td>\n",
       "      <td>1.573080e+11</td>\n",
       "      <td>396620.694151</td>\n",
       "      <td>0.404177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model            MAE           MSE           RMSE  \\\n",
       "0       Linear Regression  131319.802810  1.852624e+11  430421.150297   \n",
       "1  Support Vector Machine  215308.010480  2.748053e+11  524218.750852   \n",
       "2           Random Forest   40837.795086  1.498777e+11  387140.385611   \n",
       "3                 XGBoost   41733.465233  1.573080e+11  396620.694151   \n",
       "\n",
       "   R-squared  \n",
       "0   0.298296  \n",
       "1  -0.040858  \n",
       "2   0.432320  \n",
       "3   0.404177  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Absolute Error\n",
    "mae_linear = mean_absolute_error(y_test, y_pred_linear)\n",
    "mae_svm = mean_absolute_error(y_test, y_pred_svm)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "\n",
    "# Mean Squared Error\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "mse_svm = mean_squared_error(y_test, y_pred_svm)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "rmse_linear = np.sqrt(mse_linear)\n",
    "rmse_svm = np.sqrt(mse_svm)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "rmse_xgb = np.sqrt(mse_xgb)\n",
    "\n",
    "# R-squared\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "r2_svm = r2_score(y_test, y_pred_svm)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "metrics = {\n",
    "    'Model': ['Linear Regression', 'Support Vector Machine', 'Random Forest', 'XGBoost'],\n",
    "    'MAE': [mae_linear, mae_svm, mae_rf, mae_xgb],\n",
    "    'MSE': [mse_linear, mse_svm, mse_rf, mse_xgb],\n",
    "    'RMSE': [rmse_linear, rmse_svm, rmse_rf, rmse_xgb],\n",
    "    'R-squared': [r2_linear, r2_svm, r2_rf, r2_xgb]\n",
    "}\n",
    "\n",
    "# Create a df\n",
    "results_df = pd.DataFrame(metrics)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error (MAE) measures the average magnitude of errors in the predictions, regardless of their direction. Lower values are better. Random Forest has the lowest MAE, indicating it has the smallest average prediction error.\n",
    "\n",
    "- Best: Random Forest (40,837.80)\n",
    "Worst: Support Vector Machine (215,308.01)\n",
    "\n",
    "Mean Squared Error (MSE) measures the average of the squares of the errors. It penalizes larger errors more than MAE. Random Forest performs best here, having the lowest MSE, indicating it has the smallest average squared error.\n",
    "\n",
    "- Best model: Random Forest (1.498777e+11)\n",
    "- Worst: Support Vector Machine (2.748053e+11)\n",
    "\n",
    "Root Mean Squared Error (RMSE) is the square root of MSE and provides the error magnitude in the same units as the target variable. Random Forest has the lowest RMSE, suggesting it has the smallest error magnitude on average.\n",
    "\n",
    "- Best: Random Forest (387,140.39)\n",
    "- Worst: Support Vector Machine (524,218.75)\n",
    "\n",
    "R-squared measures the proportion of variance in the dependent variable that is predictable from the independent variables. A higher R-squared indicates a better fit. Random Forest has the highest R-squared, indicating it explains the most variance in the target variable. The Support Vector Machine has a negative R-squared, suggesting it performs worse than a simple mean-based model.\n",
    "\n",
    "- Best: Random Forest (0.432320)\n",
    "- Worst: Support Vector Machine (-0.040858)\n",
    "\n",
    "Random Forest is the best performer overall, showing the lowest MAE, MSE, and RMSE, and the highest R-squared.\n",
    "XGBoost is second, with slightly higher MAE, MSE, and RMSE but still has a high R-squared.\n",
    "Linear Regression performs reasonably well, but its metrics are not as strong as Random Forest or XGBoost.\n",
    "Support Vector Machine performs the worst in all metrics, especially in R-squared, indicating poor model performance relative to the other methods.\n",
    "\n",
    "Random Forest and XGBoost are generally more complex models that can capture non-linear relationships better than Linear Regression and Support Vector Machines in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - STRETCH\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its recommended you complete it if you have time!**\n",
    "\n",
    "Even with all the preprocessing we did in Notebook 1, you probably still have a lot of features. Are they all important for prediction?\n",
    "\n",
    "Investigate some feature selection algorithms (Lasso, RFE, Forward/Backward Selection)\n",
    "- Perform feature selection to get a reduced subset of your original features\n",
    "- Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?\n",
    "- Based on this, should you include feature selection in your final pipeline? Explain\n",
    "\n",
    "Remember, feature selection often doesn't directly improve performance, but if performance remains the same, a simpler model is often preferrable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature selection \n",
    "# refit models\n",
    "# gather evaluation metrics and compare to the previous step (full feature set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
