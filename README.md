# Data Science Midterm Project

## Group Members
- Andres : contributor
- Weronika Waszczuk: contributor

## Project/Goals

The main goals of the project were to work on and learn the following:

- Data wrangling and preprocessing for machine learning models
- Exploratory Data Analysis to understand relationships and distributions
- Model selection and evaluation techniques
- Feature selection to enhance model simplicity and performance
- Hyperparameter tuning and building a pipeline for new data

## Process
### Data wrangling and EDA
Source: All details can be found in [1 - EDA notebook](notebooks/1%20-%20EDA.ipynb)

We started by loading the raw JSON files to extract the necessary data. Next, we parsed and merged the data into a single, comprehensive dataframe.

Preprocessing Steps:

1. Data Cleaning:

    - Removed columns with completely null values.
    - Imputed or removed remaining null values.

2. Feature Engineering:

    - Performed feature aggregation for redundant columns.
    - Applied one-hot encoding to categorical columns.

3. Data Splitting:

    - Split the dataset into train and test sets to prevent data leakage before further encoding.

4. Exploratory Data Analysis (EDA):

    - Created visualizations to understand the distribution and relationships between the target variable and other features.
    - Removed highly correlated features.
    - Detected and removed outliers.

5. Scaling:

    - Scaled the data to standardize feature ranges.

Finally, we saved the preprocessed data into CSV files for further use.

### Model Selection
Source: All details can be found in [2 - Model Selection notebook](notebooks/2%20-%20model_selection%20V1.ipynb)

### Hyperparameter tuning
Source: All details can be found in [3 - Tuning Pipeline notebook](notebooks/3%20-%20tuning_pipeline.ipynb)

## Results
(fill in how your model performed)

## Challenges 
The biggest challenges faced when working on the project were:
- Handling missing values - deciding whether to impute or remove missing values and determining the best method for filling them to maintain data accuracy.
- Encoding categorical features - deciding whether and how to reduce the number of features generated by one-hot encoding.
- Preventing data leakage - ensuring that information from the test set does not inadvertently influence the training process.

## Future Goals
- Addressing stretch activities for the project - working on additional steps marked as stretch to enhance the model beyond the minimum viable product.
- Creating custom functions to increase efficiency.
- Handling outliers - analyzing how outliers influence the model and evaluating whether removing them or capping them would be more effective.
- Improving feature selection - evaluating how each feature contributes to the model's performance and retaining only those that enhance the model.
- Comparing multiple models - testing and comparing a wider range of models to identify the most effective one.
